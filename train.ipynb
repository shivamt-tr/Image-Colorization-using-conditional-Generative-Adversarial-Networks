{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T17:44:09.763829Z","iopub.status.busy":"2022-04-16T17:44:09.763573Z","iopub.status.idle":"2022-04-16T17:44:09.768554Z","shell.execute_reply":"2022-04-16T17:44:09.767792Z","shell.execute_reply.started":"2022-04-16T17:44:09.763798Z"},"id":"DZSGoBayVk-j","trusted":true},"outputs":[],"source":["# pip install fastai==2.4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["runtime = 'kaggle'  # 'local', 'colab', or 'kaggle\n","starting_epoch = 1  # Set to some other number if you want to continue training from previous checkpoint\n","upsample = False  # Set to 'True' for using upsampled generator\n","loss_type = 'l1'  # 'l1' or 'perceptual'\n","\n","pretrain_generator = False  # True if you want to pre-trained generator\n","load_pretrained_generator = False  # True if you have pre-trained weights of generator\n","batch_size = 16  # Batch size for training (change depending on how much memory you have)\n","n_epochs = 50  # Number of epochs to train for\n","lmbda = 100.  # Set-up hyper-parameter lambda for L1/Perceptual Loss term"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T17:44:11.621096Z","iopub.status.busy":"2022-04-16T17:44:11.620566Z","iopub.status.idle":"2022-04-16T17:44:11.646851Z","shell.execute_reply":"2022-04-16T17:44:11.646167Z","shell.execute_reply.started":"2022-04-16T17:44:11.621060Z"},"trusted":true},"outputs":[],"source":["if runtime == 'colab':\n","\n","    # Mount google-drive\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","    # Copy necessary files to the current environment\n","    !cp gdrive/MyDrive/Colorization/utils.py .\n","    !cp gdrive/MyDrive/Colorization/generator.py .\n","    !cp gdrive/MyDrive/Colorization/discriminator.py .\n","    !cp gdrive/MyDrive/Colorization/evaluation_metrics.py .\n","    !cp gdrive/MyDrive/Colorization/network_Lab_VGG.py .\n","    !cp gdrive/MyDrive/Colorization/perceptual_loss.py .\n","    !cp gdrive/MyDrive/Colorization/residual_upsampled_generator.py .\n","    !cp gdrive/MyDrive/Colorization/LabVGG16_BN_epoch120_batchsize32.pth .\n","\n","    # Extract the dataset in the current environment\n","    !unzip gdrive/MyDrive/Colorization/data.zip\n","    \n","if runtime == 'kaggle':\n","    import sys\n","    sys.path.insert(1, '../input/colorization/Colorization')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T17:44:14.360300Z","iopub.status.busy":"2022-04-16T17:44:14.359585Z","iopub.status.idle":"2022-04-16T17:44:14.367646Z","shell.execute_reply":"2022-04-16T17:44:14.366657Z","shell.execute_reply.started":"2022-04-16T17:44:14.360262Z"},"id":"YER73WBrVo2x","trusted":true},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","from generator import UNet\n","from discriminator import PatchGAN\n","from utils import load_transformed_batch, load_rgb_batch, init_weights, lab_to_rgb\n","from evaluation_metrics import mean_absolute_error, epsilon_accuracy, peak_signal_to_noise_ratio\n","\n","import torch\n","from torch import optim\n","from torchvision import transforms\n","\n","from residual_upsampled_generator import UNetUpsampled\n","from perceptual_loss import PerceptualLoss\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T17:44:15.563892Z","iopub.status.busy":"2022-04-16T17:44:15.563434Z","iopub.status.idle":"2022-04-16T17:44:15.585193Z","shell.execute_reply":"2022-04-16T17:44:15.584365Z","shell.execute_reply.started":"2022-04-16T17:44:15.563857Z"},"id":"fWM0nRb_iKeN","outputId":"93068261-7fff-4c0e-a847-168cebce4b72","trusted":true},"outputs":[],"source":["# Find available device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('Device:', device)\n","    \n","# Set the location of result directory\n","if runtime == 'colab':\n","    res_dir = os.path.join(os.getcwd(), 'gdrive', 'MyDrive', 'Colorization', 'results')\n","    model_dir = os.path.join(os.getcwd(), 'gdrive', 'MyDrive', 'Colorization', 'models')\n","else:\n","    res_dir = os.path.join(os.getcwd(), 'results')\n","    model_dir = os.path.join(os.getcwd(), 'models')\n","\n","# Create model and result directory if they do not exist\n","if not os.path.exists(res_dir):\n","    os.makedirs(res_dir)\n","if not os.path.exists(model_dir):\n","    os.makedirs(model_dir)\n","    \n","# Create a log file\n","if starting_epoch == 1:\n","    header = 'epoch,generator-adversarial-loss,perceptual-or-l1-loss,generator-loss-total,discriminator-loss,mae,epsilon,psnr'\n","    with open(os.path.join(res_dir, 'logs.csv'), 'w') as f:\n","        np.savetxt(f, [], delimiter=',', header=header, comments='')\n","\n","# Root directory for data\n","if runtime == 'kaggle':\n","    data_root = '../input/colorization/Colorization/data/data'\n","else:\n","    data_root = os.path.join(os.getcwd(), 'data')\n","train_dir = os.path.join(data_root, 'train')\n","test_dir = os.path.join(data_root, 'test')\n","vis_dir = os.path.join(data_root, 'visualize')\n","train_files = os.listdir(os.path.join(data_root, 'train'))\n","test_files = os.listdir(os.path.join(data_root, 'test'))\n","vis_files = os.listdir(os.path.join(data_root, 'visualize'))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T17:44:16.953502Z","iopub.status.busy":"2022-04-16T17:44:16.952896Z","iopub.status.idle":"2022-04-16T17:44:18.475365Z","shell.execute_reply":"2022-04-16T17:44:18.474335Z","shell.execute_reply.started":"2022-04-16T17:44:16.953468Z"},"id":"apXVqYUIVvek","outputId":"04d92ff1-595b-4736-8c3f-4c746a45a093","trusted":true},"outputs":[],"source":["# Display 16 randomly chosen sample images from train data\n","random_files = np.random.choice(train_files, size=16)\n","random_samples = [os.path.join(train_dir, x) for x in random_files]\n","\n","_, axes = plt.subplots(4, 4, figsize=(10, 10))\n","for ax, img_path in zip(axes.flatten(), random_samples):\n","    ax.imshow(Image.open(img_path))\n","    ax.axis(\"off\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T17:44:21.249955Z","iopub.status.busy":"2022-04-16T17:44:21.247657Z","iopub.status.idle":"2022-04-16T17:44:24.856806Z","shell.execute_reply":"2022-04-16T17:44:24.856004Z","shell.execute_reply.started":"2022-04-16T17:44:21.249913Z"},"trusted":true},"outputs":[],"source":["# Transformations for the training data\n","train_transforms = transforms.Compose([transforms.Resize((256, 256), Image.BICUBIC),\n","                                       transforms.RandomHorizontalFlip()])  # for data augmentation\n","\n","# Transformations for training upsampled architecture\n","upsample_transforms = transforms.Compose([transforms.Resize((512, 512), Image.BICUBIC),\n","                                          transforms.ToTensor()])\n","\n","# Transformations for testing the model (resize input image to suitable size for model input)\n","val_transforms = transforms.Compose([transforms.Resize((256, 256), Image.BICUBIC)])\n","\n","# Create generator object and initialize weights (normally)\n","if upsample:\n","    generator = UResNet(in_channels=1, out_channels=3, n_filters=64)\n","else:\n","    generator = UNet(in_channels=1, out_channels=2, n_filters=64)\n","generator = init_weights(generator)\n","generator.to(device)\n","\n","# Create discriminator object and initialize weights (normally)\n","discriminator = PatchGAN(in_channels=3)\n","discriminator = init_weights(discriminator)\n","discriminator.to(device)\n","\n","# Load pre-trained weights to continue training\n","if starting_epoch != 1:\n","    generator.load_state_dict(torch.load(os.path.join(model_dir, 'generator.pth'), map_location=device))\n","    discriminator.load_state_dict(torch.load(os.path.join(model_dir, 'discriminator.pth'), map_location=device))\n","        \n","# Set-up optimizer and scheduler\n","generator_optimizer = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n","discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n","\n","# Set-up loss functions\n","criterion = torch.nn.BCEWithLogitsLoss()\n","if loss_type == 'l1':\n","    additional_criterion = torch.nn.L1Loss()\n","else:\n","    additional_criterion = PerceptualLoss(color='rgb')\n","\n","# Set-up labels for real and fake predictions\n","real_label = torch.tensor(1.0)\n","fake_label = torch.tensor(0.0)\n","\n","# Calculate the number of batches\n","n_batches = int(len(train_files)/batch_size)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T17:45:32.261466Z","iopub.status.busy":"2022-04-16T17:45:32.261212Z","iopub.status.idle":"2022-04-16T17:45:35.377709Z","shell.execute_reply":"2022-04-16T17:45:35.376924Z","shell.execute_reply.started":"2022-04-16T17:45:32.261439Z"},"trusted":true},"outputs":[],"source":["if load_pretrained_generator:\n","    \n","    from fastai.vision.learner import create_body\n","    from torchvision.models.resnet import resnet18\n","    from fastai.vision.models.unet import DynamicUnet\n","    \n","    body = create_body(resnet18, pretrained=True, n_in=1, cut=-2)\n","    generator = DynamicUnet(body, n_out=2, img_size=(256, 256)).to(device)\n","    generator.load_state_dict(torch.load(os.path.join('../input/colorization/generator_pretrained.pth'), map_location=device))\n","\n","# Pre-training the generator for 20 epochs\n","if pretrain_generator:\n","    \n","    from fastai.vision.learner import create_body\n","    from torchvision.models.resnet import resnet18\n","    from fastai.vision.models.unet import DynamicUnet\n","    \n","    print('Pre-training the Generator')\n","\n","    body = create_body(resnet18, pretrained=True, n_in=1, cut=-2)\n","    generator = DynamicUnet(body, n_out=2, img_size=(256, 256)).to(device)\n","\n","    pretrain_generator_optimizer = optim.Adam(generator.parameters(), lr=1e-4)\n","\n","    for epoch in range(1, 20+1):\n","\n","        print('Epoch {}/{}'.format(epoch, 20))\n","        print('-' * 10)\n","\n","        running_generator_loss_l1 = 0.0\n","\n","        generator.train()\n","\n","        # Iterate over all the batches\n","        for j in tqdm(range(n_batches), desc='Batch'):\n","\n","            # Get the train data and labels for the current batch\n","            batch_files = train_files[j*batch_size:(j+1)*batch_size]\n","            L, ab = load_transformed_batch(train_dir, batch_files, train_transforms)\n","            \n","            # Put the data to the device\n","            L, ab = L.to(device), ab.to(device)\n","\n","            with torch.set_grad_enabled(True):\n","\n","                # Run the batch through the generator\n","                output = generator(L)\n","\n","                # Calculate the loss\n","                generator_loss_l1 = additional_criterion(output, ab)\n","\n","                # Make gradients zero\n","                pretrain_generator_optimizer.zero_grad()\n","\n","                # backward + optimize\n","                generator_loss_l1.backward()\n","                pretrain_generator_optimizer.step()\n","\n","            running_generator_loss_l1 += generator_loss_l1.item() * batch_size\n","\n","        # Calculate average loss for current epoch\n","        epoch_generator_loss_l1 = running_generator_loss_l1 / (n_batches*batch_size)\n","\n","        print('Generator Loss: {:.4f}'.format(epoch_generator_loss_l1))\n","\n","        # Save the generator and discriminator model\n","        torch.save(generator.state_dict(), os.path.join(model_dir, 'generator_pretrained.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T17:45:40.963930Z","iopub.status.busy":"2022-04-16T17:45:40.963670Z"},"trusted":true},"outputs":[],"source":["# Adversarial Training\n","for epoch in range(starting_epoch, n_epochs+1):\n","    \n","    # Variable to record time taken in each epoch\n","    since = time.time()\n","    \n","    print('Epoch {}/{}'.format(epoch, n_epochs))\n","    print('-' * 10)\n","\n","    running_generator_loss_adversarial = 0.0\n","    running_generator_loss_additional = 0.0\n","    running_generator_loss_total = 0.0\n","    running_discriminator_loss_total = 0.0\n","    running_mae = 0.0\n","    running_epsilon = 0.0\n","    running_psnr = 0.0\n","    \n","    # Iterate over all the batches\n","    for j in tqdm(range(n_batches), desc='Batch'):\n","            \n","        # Get the train data and labels for the current batch\n","        batch_files = train_files[j*batch_size:(j+1)*batch_size]\n","        L, ab = load_transformed_batch(train_dir, batch_files, train_transforms)\n","        \n","        # Put the data to the device\n","        L, ab = L.to(device), ab.to(device)\n","        \n","        if upsample:\n","            rgb_images = load_rgb_batch(train_dir, batch_files, upsample_transforms)\n","            rgb_images = rgb_images.to(device)\n","        \n","        # Create a fake color image using the generator\n","        fake_color = generator(L)\n","\n","        # Train the discriminator\n","        discriminator.train()\n","\n","        # Enable grads\n","        for p in discriminator.parameters():\n","            p.requires_grad = True\n","\n","        # Make gradients zero before forward pass\n","        discriminator_optimizer.zero_grad()\n","\n","        # Run fake examples through the discriminator\n","        if upsample:\n","            fake_image = fake_color    \n","        else:\n","            fake_image = torch.cat([L, fake_color], dim=1)  # Make dim=0 when passing only one sample\n","        fake_preds = discriminator(fake_image.detach())\n","        discriminator_loss_fake = criterion(fake_preds, fake_label.expand_as(fake_preds).to(device))\n","        \n","        # Run real examples through the discriminator\n","        if upsample:\n","            real_image = rgb_images  \n","        else:\n","            real_image = torch.cat([L, ab], dim=1)  # Make dim=0 when passing only one sample\n","        real_preds = discriminator(real_image)\n","        discriminator_loss_real = criterion(real_preds, real_label.expand_as(real_preds).to(device))\n","        \n","        # Total loss is the sum of both the losses\n","        discriminator_loss_total = (discriminator_loss_fake + discriminator_loss_real) * 0.5\n","        \n","        # backward + optimize\n","        discriminator_loss_total.backward()\n","        discriminator_optimizer.step()\n","        \n","        # Train the generator while keeping the discriminator weights constant\n","        generator.train()\n","        \n","        # Enable grads\n","        for p in discriminator.parameters():\n","            p.requires_grad = False\n","\n","        # Make gradients zero before forward pass\n","        generator_optimizer.zero_grad()\n","\n","        # Calculate the prediction using discriminator\n","        fake_preds = discriminator(fake_image)\n","        \n","        # Calculate adversarial loss for the generator\n","        generator_loss_adversarial = criterion(fake_preds, real_label.expand_as(real_preds).to(device))\n","        \n","        # Calculate L1 loss for the generator (lambda * L1_loss)\n","        # Total loss is the sum of both the losses\n","        if loss_type == 'l1':\n","            generator_loss_additional = additional_criterion(fake_color, ab) * lmbda\n","            generator_loss_total = generator_loss_adversarial + generator_loss_additional\n","        else:\n","            generator_loss_additional = additional_criterion(fake_image, real_image)\n","            generator_loss_total = generator_loss_adversarial + generator_loss_additional\n","        \n","        # backward + optimize\n","        generator_loss_total.backward()\n","        generator_optimizer.step()\n","        \n","        # Add up the accuracy and losses for current batch\n","        running_generator_loss_adversarial += generator_loss_adversarial.item() * batch_size\n","        running_generator_loss_additional += generator_loss_additional.item() * batch_size\n","        running_generator_loss_total += generator_loss_total.item() * batch_size\n","        running_discriminator_loss_total += discriminator_loss_total.item() * batch_size\n","        \n","        if upsample:\n","            real_image_array = rgb_images\n","            fake_image_array = fake_image   \n","        else:\n","            real_image_array = torch.from_numpy(lab_to_rgb(L.detach(), ab.detach()))\n","            fake_image_array = torch.from_numpy(lab_to_rgb(L.detach(), fake_color.detach()))\n","        \n","        running_mae += mean_absolute_error(real_image_array, fake_image_array) * batch_size\n","        running_epsilon += epsilon_accuracy(real_image_array, fake_image_array, epsilon=0.05) * batch_size  # epsilon set at 5% of 255\n","        running_psnr += peak_signal_to_noise_ratio(real_image_array, fake_image_array) * batch_size\n","\n","    # Calculate the average accuracy and average loss for current epoch\n","    epoch_generator_loss_adversarial = running_generator_loss_adversarial / (n_batches*batch_size)\n","    epoch_generator_loss_additional = running_generator_loss_additional / (n_batches*batch_size)\n","    epoch_generator_loss_total = running_generator_loss_total / (n_batches*batch_size)\n","    epoch_discriminator_loss_total = running_discriminator_loss_total / (n_batches*batch_size)\n","    epoch_mae = running_mae / (n_batches*batch_size)\n","    epoch_epsilon = running_epsilon / (n_batches*batch_size)\n","    epoch_psnr = running_psnr / (n_batches*batch_size)\n","    \n","    print('Generator Loss Adversarial: {:.4f}'.format(epoch_generator_loss_adversarial))\n","    print('Generator Loss L1/Perceptual: {:.4f}'.format(epoch_generator_loss_additional))\n","    print('Generator Loss Total: {:.4f}'.format(epoch_generator_loss_total))\n","    print('Discriminator Loss Total: {:.4f}'.format(epoch_discriminator_loss_total))\n","    print('Mean Absolute Error: {:.4f}'.format(epoch_mae))\n","    print('Epsilon Accuracy: {:.4f}'.format(epoch_epsilon))\n","    print('Peak SNR: {:.4f}'.format(epoch_psnr))\n","    \n","    time_elapsed = time.time() - since\n","    print('Epoch complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    \n","    # Save the generator and discriminator model\n","    torch.save(generator.state_dict(), os.path.join(model_dir, 'generator.pth'))\n","    torch.save(discriminator.state_dict(), os.path.join(model_dir, 'discriminator.pth'))\n","    \n","    # Save loss and accuracy to log file\n","    log = [[epoch,\n","            epoch_generator_loss_adversarial,\n","            epoch_generator_loss_additional,\n","            epoch_generator_loss_total,\n","            epoch_discriminator_loss_total,\n","            epoch_mae,\n","            epoch_epsilon,\n","            epoch_psnr]]\n","    with open(os.path.join(res_dir, 'logs.csv'), 'a') as f:\n","        np.savetxt(f, log, delimiter=',')\n","    \n","    # Test the model on 50 sample images to visualize the colorization\n","    generator.eval()\n","\n","    with torch.no_grad():\n","    \n","        # Transform the images and get their L and ab channels\n","        L, ab = load_transformed_batch(vis_dir, vis_files, val_transforms)\n","        L, ab = L.to(device), ab.to(device)\n","        \n","        if upsample:\n","            # Run the L channel through the generator to get 'rgb' results\n","            res_images = generator(L).permute(0, 2, 3, 1).detach().numpy()\n","            # res_images = output_to_rgb(res_images)\n","        else:\n","            # Run the L channel through the generator to get 'ab' channels\n","            res_images = lab_to_rgb(L, generator(L))\n","            \n","        # Create directory for saving visualizations of images for the current epoch\n","        vis_result_dir = os.path.join(res_dir, 'epoch '+str(epoch))\n","        if not os.path.exists(vis_result_dir):\n","            os.makedirs(vis_result_dir)\n","        \n","        # Save output images for this epoch\n","        for i in range(len(res_images)):\n","            image = res_images[i] * 255\n","            Image.fromarray(image.astype(np.uint8)).save(os.path.join(vis_result_dir, vis_files[i]))\n","            \n","    generator.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
